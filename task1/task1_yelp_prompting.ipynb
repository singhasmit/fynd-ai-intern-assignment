{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdbe8c6b-761e-4a58-8d06-4ea11d9da0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List , Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b8de39-456f-4379-961d-77e1888a9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/yelp.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362db74f-2933-49c6-963d-88d85b1179ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only the column that we need that is the text as review and stars as the review rating\n",
    "df = df[[\"text\", \"stars\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79cfd8ef-6f02-4043-852b-e1e75590b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d068c37-19e2-4ca4-8f61-124f06ccdc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       "                                                 text  stars\n",
       " 0  We got here around midnight last Friday... the...      4\n",
       " 1  Brought a friend from Louisiana here.  She say...      5\n",
       " 2  Every friday, my dad and I eat here. We order ...      3\n",
       " 3  My husband and I were really, really disappoin...      1\n",
       " 4  Love this place!  Was in phoenix 3 weeks for w...      5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df.sample(15, random_state=42).reset_index(drop=True)\n",
    "len(df_small), df_small.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d195ca2e-891c-4cc0-8e2c-7d7ba2904c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt V1: Simple JSON classification\n",
    "prompt_v1 = \"\"\"\n",
    "You are an expert Yelp review analyst.\n",
    "\n",
    "Task:\n",
    "- Read the review text.\n",
    "- Decide the most appropriate star rating from 1 to 5.\n",
    "\n",
    "Return the result as a single JSON object with this exact structure:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <number from 1 to 5>,\n",
    "  \"explanation\": \"<very brief reason for the rating>\"\n",
    "}}\n",
    "\n",
    "Respond with JSON only. No extra text.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n",
    "\n",
    "# Prompt V2: Step-by-step reasoning + JSON\n",
    "prompt_v2 = \"\"\"\n",
    "You are an expert sentiment analyst for Yelp restaurant reviews.\n",
    "\n",
    "Follow these steps in your head:\n",
    "1. Identify key positive and negative points in the review.\n",
    "2. Decide what star rating (1–5) a typical Yelp user would give.\n",
    "3. Consider review length and intensity of sentiment.\n",
    "\n",
    "Then respond ONLY with a single JSON object of this form:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <number from 1 to 5>,\n",
    "  \"explanation\": \"<1–2 short sentences summarizing your reasoning>\"\n",
    "}}\n",
    "\n",
    "Do not add any text outside the JSON.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n",
    "\n",
    "# Prompt V3: Few-shot examples + JSON\n",
    "prompt_v3 = \"\"\"\n",
    "You are an expert Yelp review rating assistant.\n",
    "\n",
    "Below are examples of how you should think and respond.\n",
    "\n",
    "Example 1\n",
    "Review: \"Terrible service. Food was cold and tasteless. I will never come back.\"\n",
    "Response:\n",
    "{{\n",
    "  \"predicted_stars\": 1,\n",
    "  \"explanation\": \"Very negative sentiment about both service and food.\"\n",
    "}}\n",
    "\n",
    "Example 2\n",
    "Review: \"Pretty good burger and fries. Service was fine, nothing special.\"\n",
    "Response:\n",
    "{{\n",
    "  \"predicted_stars\": 4,\n",
    "  \"explanation\": \"Overall positive with only minor issues.\"\n",
    "}}\n",
    "\n",
    "Now analyze the NEW review below and respond in the SAME JSON format:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <number from 1 to 5>,\n",
    "  \"explanation\": \"<brief explanation>\"\n",
    "}}\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a2bb06-ade4-4a3b-991d-4ae0824e72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asmit\\anaconda3\\envs\\fynd\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable not set.\")\n",
    "    \n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc31fbee-90d8-4956-98d5-7659d3fa586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai import GenerativeModel\n",
    "gemini_model = GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b344190e-dafd-4460-bda9-ded459dd453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now writing rating predictor function\n",
    "import json\n",
    "import re\n",
    "\n",
    "def parse_model_output(output: str):\n",
    "    \"\"\"\n",
    "    Try to extract a JSON object with `predicted_stars` and `explanation`\n",
    "    from the model output.\n",
    "\n",
    "    Returns:\n",
    "        predicted (int), json_valid (bool)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Try direct JSON first\n",
    "    try:\n",
    "        data = json.loads(output)\n",
    "        rating = int(data[\"predicted_stars\"])\n",
    "        if 1 <= rating <= 5 and \"explanation\" in data:\n",
    "            return rating, True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Try to extract the first {...} block from the text\n",
    "    try:\n",
    "        match = re.search(r\"\\{.*\\}\", output, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group(0)\n",
    "            # Try parsing that substring\n",
    "            data = json.loads(json_str)\n",
    "            rating = int(data[\"predicted_stars\"])\n",
    "            if 1 <= rating <= 5 and \"explanation\" in data:\n",
    "                return rating, True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) Last-resort: only extract rating digit from the text\n",
    "    m = re.search(r\"[1-5]\", output)\n",
    "    if m:\n",
    "        rating = int(m.group())\n",
    "    else:\n",
    "        rating = 3  # neutral fallback\n",
    "\n",
    "    return rating, False\n",
    "\n",
    "\n",
    "def gemini_call(review_text: str, prompt_template: str):\n",
    "    \"\"\"\n",
    "    Call Gemini with a given prompt template and review text.\n",
    "\n",
    "    Returns:\n",
    "        predicted_rating (int)\n",
    "        json_valid (bool)\n",
    "        raw_output (str)\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(review_text=review_text)\n",
    "\n",
    "    try:\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        output = response.text.strip()\n",
    "\n",
    "        predicted, json_valid = parse_model_output(output)\n",
    "        return predicted, json_valid, output\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error calling Gemini:\", e)\n",
    "        # safe fallback\n",
    "        return 3, False, \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd686a8c-8e16-4cf8-9a55-eb478a1adf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_predictions(df, prompt_template, sleep_sec=4):\n",
    "    preds = []\n",
    "    json_flags = []\n",
    "    raw_outputs = []\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        review = row[\"text\"]\n",
    "        rating, json_valid, raw = gemini_call(review, prompt_template)\n",
    "\n",
    "        preds.append(rating)\n",
    "        json_flags.append(json_valid)\n",
    "        raw_outputs.append(raw)\n",
    "\n",
    "        print(f\"Processed {idx+1}/{total}\")\n",
    "        time.sleep(sleep_sec)   \n",
    "\n",
    "    df_out = df.copy()\n",
    "    df_out[\"pred_rating\"] = preds\n",
    "    df_out[\"json_valid\"] = json_flags\n",
    "    df_out[\"raw_output\"] = raw_outputs\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f60526-796e-403f-a8f8-ef708c605d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "Processed 1/15\n",
      "Error calling Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "Processed 2/15\n",
      "Error calling Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "Processed 3/15\n",
      "Error calling Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "Processed 4/15\n",
      "Error calling Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "Processed 5/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_v1 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_v1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_v2 \u001b[38;5;241m=\u001b[39m run_predictions(df_small, prompt_v2)\n\u001b[0;32m      3\u001b[0m df_v3 \u001b[38;5;241m=\u001b[39m run_predictions(df_small, prompt_v3)\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mrun_predictions\u001b[1;34m(df, prompt_template, sleep_sec)\u001b[0m\n\u001b[0;32m     16\u001b[0m     raw_outputs\u001b[38;5;241m.\u001b[39mappend(raw)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_sec\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[0;32m     21\u001b[0m df_out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     22\u001b[0m df_out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_v1 = run_predictions(df_small, prompt_v1)\n",
    "df_v2 = run_predictions(df_small, prompt_v2)\n",
    "df_v3 = run_predictions(df_small, prompt_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f27cd-b6d3-45a3-b2f3-90eade8da565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_prompt_results(df_results, name=\"\"):\n",
    "    y_true = df_results[\"stars\"].astype(int)\n",
    "    y_pred = df_results[\"pred_rating\"].astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    json_valid_rate = df_results[\"json_valid\"].mean()\n",
    "\n",
    "    print(f\"-->{name}<--\")\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"JSON validity rate: {json_valid_rate:.3f}\")\n",
    "    return {\n",
    "        \"prompt\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"json_valid_rate\": json_valid_rate\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc20ddd-249d-43b5-b8db-2f4b569ed557",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_v1 = evaluate_prompt_results(df_v1, \"V1: Simple JSON\")\n",
    "metrics_v2 = evaluate_prompt_results(df_v2, \"V2: Reasoning JSON\")\n",
    "metrics_v3 = evaluate_prompt_results(df_v3, \"V3: Few-shot JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae97bd6-9732-4547-92ed-eecf766de216",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame([metrics_v1, metrics_v2, metrics_v3])\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1c584-c776-4ff2-8b3f-fe02c4de72e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
