{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdbe8c6b-761e-4a58-8d06-4ea11d9da0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List , Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b8de39-456f-4379-961d-77e1888a9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/yelp.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362db74f-2933-49c6-963d-88d85b1179ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only the column that we need that is the text as review and stars as the review rating\n",
    "df = df[[\"text\", \"stars\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79cfd8ef-6f02-4043-852b-e1e75590b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d068c37-19e2-4ca4-8f61-124f06ccdc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       "                                                 text  stars\n",
       " 0  We got here around midnight last Friday... the...      4\n",
       " 1  Brought a friend from Louisiana here.  She say...      5\n",
       " 2  Every friday, my dad and I eat here. We order ...      3\n",
       " 3  My husband and I were really, really disappoin...      1\n",
       " 4  Love this place!  Was in phoenix 3 weeks for w...      5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df.sample(5, random_state=42).reset_index(drop=True)\n",
    "len(df_small), df_small.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d195ca2e-891c-4cc0-8e2c-7d7ba2904c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt V1: Simple JSON classification\n",
    "prompt_v1 = \"\"\"\n",
    "You are an expert Yelp review analyst.\n",
    "\n",
    "Task:\n",
    "- Read the review text.\n",
    "- Decide the most appropriate star rating from 1 to 5.\n",
    "\n",
    "Return the result as a single JSON object with this exact structure:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <number from 1 to 5>,\n",
    "  \"explanation\": \"<very brief reason for the rating>\"\n",
    "}}\n",
    "\n",
    "Respond with JSON only. No extra text.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n",
    "\n",
    "# Prompt V2: Step-by-step reasoning + JSON\n",
    "prompt_v2 = \"\"\"\n",
    "You are an expert sentiment analyst for Yelp restaurant reviews.\n",
    "\n",
    "Follow these steps in your head:\n",
    "1. Identify key positive and negative points in the review.\n",
    "2. Decide what star rating (1–5) a typical Yelp user would give.\n",
    "3. Consider review length and intensity of sentiment.\n",
    "\n",
    "Then respond ONLY with a single JSON object of this form:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <number from 1 to 5>,\n",
    "  \"explanation\": \"<1–2 short sentences summarizing your reasoning>\"\n",
    "}}\n",
    "\n",
    "Do not add any text outside the JSON.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n",
    "\n",
    "# Prompt V3: Few-shot examples + JSON\n",
    "prompt_v3 = \"\"\"\n",
    "You are an expert Yelp review rating assistant.\n",
    "\n",
    "Below are examples of how you should think and respond.\n",
    "\n",
    "Example 1\n",
    "Review: \"Terrible service. Food was cold and tasteless. I will never come back.\"\n",
    "Response:\n",
    "{{\n",
    "  \"predicted_stars\": 1,\n",
    "  \"explanation\": \"Very negative sentiment about both service and food.\"\n",
    "}}\n",
    "\n",
    "Example 2\n",
    "Review: \"Pretty good burger and fries. Service was fine, nothing special.\"\n",
    "Response:\n",
    "{{\n",
    "  \"predicted_stars\": 4,\n",
    "  \"explanation\": \"Overall positive with only minor issues.\"\n",
    "}}\n",
    "\n",
    "Now analyze the NEW review below and respond in the SAME JSON format:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <number from 1 to 5>,\n",
    "  \"explanation\": \"<brief explanation>\"\n",
    "}}\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a2bb06-ade4-4a3b-991d-4ae0824e72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asmit\\anaconda3\\envs\\fynd\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "api_key =os.getenv(\"GEMINI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable not set.\")\n",
    "    \n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc31fbee-90d8-4956-98d5-7659d3fa586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai import GenerativeModel\n",
    "gemini_model = GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b344190e-dafd-4460-bda9-ded459dd453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now writing rating predictor function\n",
    "import json\n",
    "import re\n",
    "\n",
    "def parse_model_output(output: str):\n",
    "    \n",
    "    # 1) Try direct JSON first\n",
    "    try:\n",
    "        data = json.loads(output)\n",
    "        rating = int(data[\"predicted_stars\"])\n",
    "        if 1 <= rating <= 5 and \"explanation\" in data:\n",
    "            return rating, True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Try to extract the first {...} block from the text\n",
    "    try:\n",
    "        match = re.search(r\"\\{.*\\}\", output, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group(0)\n",
    "            # Try parsing that substring\n",
    "            data = json.loads(json_str)\n",
    "            rating = int(data[\"predicted_stars\"])\n",
    "            if 1 <= rating <= 5 and \"explanation\" in data:\n",
    "                return rating, True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) Last-resort: only extract rating digit from the text\n",
    "    m = re.search(r\"[1-5]\", output)\n",
    "    if m:\n",
    "        rating = int(m.group())\n",
    "    else:\n",
    "        rating = 3  # neutral fallback\n",
    "\n",
    "    return rating, False\n",
    "\n",
    "\n",
    "def gemini_call(review_text: str, prompt_template: str):\n",
    "    \"\"\"\n",
    "    Call Gemini with a given prompt template and review text.\n",
    "\n",
    "    Returns:\n",
    "        predicted_rating (int)\n",
    "        json_valid (bool)\n",
    "        raw_output (str)\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(review_text=review_text)\n",
    "\n",
    "    try:\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        output = response.text.strip()\n",
    "\n",
    "        predicted, json_valid = parse_model_output(output)\n",
    "        return predicted, json_valid, output\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error calling Gemini:\", e)\n",
    "        # safe fallback\n",
    "        return 3, False, \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd686a8c-8e16-4cf8-9a55-eb478a1adf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_predictions(df, prompt_template, sleep_sec=4):\n",
    "    preds = []\n",
    "    json_flags = []\n",
    "    raw_outputs = []\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        review = row[\"text\"]\n",
    "        rating, json_valid, raw = gemini_call(review, prompt_template)\n",
    "\n",
    "        preds.append(rating)\n",
    "        json_flags.append(json_valid)\n",
    "        raw_outputs.append(raw)\n",
    "\n",
    "        print(f\"Processed {idx+1}/{total}\")\n",
    "        time.sleep(sleep_sec)   \n",
    "\n",
    "    df_out = df.copy()\n",
    "    df_out[\"pred_rating\"] = preds\n",
    "    df_out[\"json_valid\"] = json_flags\n",
    "    df_out[\"raw_output\"] = raw_outputs\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f60526-796e-403f-a8f8-ef708c605d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/5\n",
      "Processed 2/5\n",
      "Processed 3/5\n",
      "Processed 4/5\n",
      "Processed 5/5\n",
      "Processed 1/5\n",
      "Processed 2/5\n",
      "Processed 3/5\n",
      "Processed 4/5\n",
      "Error calling Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 57.692780326s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "Processed 5/5\n",
      "Error calling Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 53.201019882s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "]\n",
      "Processed 1/5\n",
      "Error calling Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 48.817393286s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "]\n",
      "Processed 2/5\n",
      "Processed 3/5\n",
      "Processed 4/5\n",
      "Processed 5/5\n"
     ]
    }
   ],
   "source": [
    "df_v1 = run_predictions(df_small, prompt_v1)\n",
    "df_v2 = run_predictions(df_small, prompt_v2)\n",
    "df_v3 = run_predictions(df_small, prompt_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0f27cd-b6d3-45a3-b2f3-90eade8da565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_prompt_results(df_results, name=\"\"):\n",
    "    y_true = df_results[\"stars\"].astype(int)\n",
    "    y_pred = df_results[\"pred_rating\"].astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    json_valid_rate = df_results[\"json_valid\"].mean()\n",
    "\n",
    "    print(f\"-->{name}<--\")\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"JSON validity rate: {json_valid_rate:.3f}\")\n",
    "    return {\n",
    "        \"prompt\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"json_valid_rate\": json_valid_rate\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc20ddd-249d-43b5-b8db-2f4b569ed557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->V1: Simple JSON<--\n",
      "Accuracy: 0.600\n",
      "JSON validity rate: 1.000\n",
      "-->V2: Reasoning JSON<--\n",
      "Accuracy: 0.400\n",
      "JSON validity rate: 0.800\n",
      "-->V3: Few-shot JSON<--\n",
      "Accuracy: 0.400\n",
      "JSON validity rate: 0.600\n"
     ]
    }
   ],
   "source": [
    "metrics_v1 = evaluate_prompt_results(df_v1, \"V1: Simple JSON\")\n",
    "metrics_v2 = evaluate_prompt_results(df_v2, \"V2: Reasoning JSON\")\n",
    "metrics_v3 = evaluate_prompt_results(df_v3, \"V3: Few-shot JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae97bd6-9732-4547-92ed-eecf766de216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>json_valid_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1: Simple JSON</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V2: Reasoning JSON</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V3: Few-shot JSON</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               prompt  accuracy  json_valid_rate\n",
       "0     V1: Simple JSON       0.6              1.0\n",
       "1  V2: Reasoning JSON       0.4              0.8\n",
       "2   V3: Few-shot JSON       0.4              0.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([metrics_v1, metrics_v2, metrics_v3])\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1c584-c776-4ff2-8b3f-fe02c4de72e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f85ff-4084-4b71-a45b-6f05608c9274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fynd]",
   "language": "python",
   "name": "conda-env-fynd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
